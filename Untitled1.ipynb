{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a42c3af0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plugin_event_multiplexer \u001b[38;5;28;01mas\u001b[39;00m event_multiplexer  \u001b[38;5;66;03m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Control downsampling: how many scalar data do we keep for each run/tag\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# combination?\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import csv\n",
    "import errno\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.backend.event_processing import plugin_event_multiplexer as event_multiplexer  # pylint: disable=line-too-long\n",
    "\n",
    "\n",
    "# Control downsampling: how many scalar data do we keep for each run/tag\n",
    "# combination?\n",
    "SIZE_GUIDANCE = {'scalars': 1000}\n",
    "\n",
    "\n",
    "def extract_scalars(multiplexer, run, tag):\n",
    "  \"\"\"Extract tabular data from the scalars at a given run and tag.\n",
    "  The result is a list of 3-tuples (wall_time, step, value).\n",
    "  \"\"\"\n",
    "  tensor_events = multiplexer.Tensors(run, tag)\n",
    "  return [\n",
    "      (event.wall_time, event.step, tf.make_ndarray(event.tensor_proto).item())\n",
    "      for event in tensor_events\n",
    "  ]\n",
    "\n",
    "\n",
    "def create_multiplexer(logdir):\n",
    "  multiplexer = event_multiplexer.EventMultiplexer(\n",
    "      tensor_size_guidance=SIZE_GUIDANCE)\n",
    "  multiplexer.AddRunsFromDirectory(logdir)\n",
    "  multiplexer.Reload()\n",
    "  return multiplexer\n",
    "\n",
    "\n",
    "def export_scalars(multiplexer, run, tag, filepath, write_headers=True):\n",
    "  data = extract_scalars(multiplexer, run, tag)\n",
    "  with open(filepath, 'w') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    if write_headers:\n",
    "      writer.writerow(('wall_time', 'step', 'value'))\n",
    "    for row in data:\n",
    "      writer.writerow(row)\n",
    "\n",
    "\n",
    "NON_ALPHABETIC = re.compile('[^A-Za-z0-9_]')\n",
    "\n",
    "def munge_filename(name):\n",
    "  \"\"\"Remove characters that might not be safe in a filename.\"\"\"\n",
    "  return NON_ALPHABETIC.sub('_', name)\n",
    "\n",
    "\n",
    "def mkdir_p(directory):\n",
    "  try:\n",
    "    os.makedirs(directory)\n",
    "  except OSError as e:\n",
    "    if not (e.errno == errno.EEXIST and os.path.isdir(directory)):\n",
    "      raise\n",
    "\n",
    "\n",
    "def main():\n",
    "  run_names = (\n",
    "      'scalars_demo/temperature:t0=270,tA=270,kH=%s' % x\n",
    "      for x in ('0.001', '0.005')\n",
    "  )\n",
    "  tag_names = ('temperature/current/scalar_summary', 'delta/scalar_summary')\n",
    "\n",
    "  logdir = '/tmp/data'\n",
    "  output_dir = '/tmp/csv_output'\n",
    "  mkdir_p(output_dir)\n",
    "\n",
    "  print(\"Loading data...\")\n",
    "  multiplexer = create_multiplexer(logdir)\n",
    "  for run_name in run_names:\n",
    "    for tag_name in tag_names:\n",
    "      output_filename = '%s___%s' % (\n",
    "          munge_filename(run_name), munge_filename(tag_name))\n",
    "      output_filepath = os.path.join(output_dir, output_filename)\n",
    "      print(\n",
    "          \"Exporting (run=%r, tag=%r) to %r...\"\n",
    "          % (run_name, tag_name, output_filepath))\n",
    "      export_scalars(multiplexer, run_name, tag_name, output_filepath)\n",
    "  print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
